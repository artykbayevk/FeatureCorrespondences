{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using Distances\n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using JuMP\n",
    "using Gurobi\n",
    "using CSV\n",
    "using DataFrames\n",
    "using SparseArrays\n",
    "using Printf\n",
    "using JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size P points(100, 2)\n",
      "size Q points(100, 2)\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "py\"\"\"\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class Triangulation:\n",
    "    def load_imgs(self, path1, path2):\n",
    "        self.img1 = cv2.imread(path1, cv2.CV_8UC3)\n",
    "        self.img2 = cv2.imread(path2, cv2.CV_8UC3)\n",
    "        # base = \"/\".join(path1.split(\"\\\\\")[:-1])\n",
    "        # cv2.imwrite(os.path.join(base, \"left_loaded.png\"), self.img1)\n",
    "        # cv2.imwrite(os.path.join(base, \"right_loaded.png\"), self.img2)\n",
    "    \n",
    "    def findK_centroids(self, features, clusters):\n",
    "        class InnerFeatures:\n",
    "            def __init__(self, kps, des, pos):\n",
    "                self.kps = kps\n",
    "                self.des = des\n",
    "                self.pos = pos\n",
    "\n",
    "        kmeans = KMeans(n_clusters=clusters)\n",
    "\n",
    "        pts = np.array(features.pos)\n",
    "        kps = np.array(features.kps)\n",
    "        des = np.array(features.des)\n",
    "\n",
    "        kmeans.fit(pts)\n",
    "        m_clusters = kmeans.labels_.tolist()\n",
    "        centers = np.array(kmeans.cluster_centers_)\n",
    "\n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, pts)\n",
    "\n",
    "        assert len(set(closest)) == clusters\n",
    "\n",
    "        result = InnerFeatures(kps[closest], des[closest], pts[closest])\n",
    "        return result\n",
    "\n",
    "    def findK_centroids_average(self, features, clusters):\n",
    "        class InnerFeatures:\n",
    "            def __init__(self, kps, des, pos):\n",
    "                self.kps = kps\n",
    "                self.des = des\n",
    "                self.pos = pos\n",
    "        kmeans = KMeans(n_clusters=clusters)\n",
    "\n",
    "        pts = np.array(features.pos)\n",
    "        kps = np.array(features.kps)\n",
    "        des = np.array(features.des)\n",
    "\n",
    "        kmeans.fit(pts)\n",
    "        m_clusters = np.array(kmeans.labels_.tolist())\n",
    "        centers = np.array(kmeans.cluster_centers_)\n",
    "\n",
    "        # KeyPoint(x,y,size) -required\n",
    "\n",
    "        final_kps = []\n",
    "        final_des = []\n",
    "        final_pts = []\n",
    "\n",
    "        for cluster in range(clusters):\n",
    "            indices = np.where(m_clusters == cluster)\n",
    "            cluster_kps_size = np.mean(np.array([x.size for x in kps[indices]]))\n",
    "            cluster_des = des[indices]\n",
    "\n",
    "            average_des = np.mean(cluster_des, axis=0)\n",
    "            cluster_kps = cv2.KeyPoint(x=centers[cluster][0], y=centers[cluster][1], _size=cluster_kps_size)\n",
    "\n",
    "            final_kps.append(cluster_kps)\n",
    "            final_des.append(average_des)\n",
    "            final_pts.append([centers[cluster][0], centers[cluster][1]])\n",
    "\n",
    "        final_pts = np.array(final_pts)\n",
    "        final_des = np.array(final_des)\n",
    "        final_kps = np.array(final_kps)\n",
    "\n",
    "        result = InnerFeatures(kps = final_kps, des=final_des, pos = final_pts)\n",
    "        return result\n",
    "\n",
    "    def findRootSIFTFeatures(self, n_components = None):\n",
    "        class RootSIFT:\n",
    "            def __init__(self):\n",
    "                self.extractor =  cv2.xfeatures2d.SIFT_create()\n",
    "            def compute(self, image, kps, eps=1e-7):\n",
    "                (kps, descs) = self.extractor.compute(image, kps)\n",
    "                if len(kps) == 0:\n",
    "                    return ([], None)\n",
    "\n",
    "                descs /= (descs.sum(axis=1, keepdims=True) + eps)\n",
    "                descs = np.sqrt(descs)\n",
    "                return (kps, descs)\n",
    "\n",
    "        class InnerFeatures:\n",
    "            def __init__(self, kps, des, pos):\n",
    "                self.kps = kps\n",
    "                self.des = des\n",
    "                self.pos = pos\n",
    "\n",
    "        def innerRootSIFT(img):\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "            (kps, descs) = sift.detectAndCompute(img, None)\n",
    "\n",
    "            rs = RootSIFT()\n",
    "            (kps, descs) = rs.compute(img, kps)\n",
    "            pos = [np.array([x.pt[0], x.pt[1]]) for x in kps]\n",
    "\n",
    "            return kps, descs, pos\n",
    "\n",
    "        kps1, desc1, pos1 = innerRootSIFT(self.img1)\n",
    "        kps2, desc2, pos2 = innerRootSIFT(self.img2)\n",
    "        self.feature_1 = InnerFeatures(kps1, desc1, pos1)\n",
    "        self.feature_2 = InnerFeatures(kps2, desc2, pos2)\n",
    "        \n",
    "        ## TOP K CENTROIDS\n",
    "        self.feature_1 = self.findK_centroids_average(self.feature_1, n_components)\n",
    "        self.feature_2 = self.findK_centroids_average(self.feature_2, n_components)\n",
    "\n",
    "        \n",
    "    def drawMatches(self, path):\n",
    "        self.outImage = cv2.drawMatches(self.img1, self.feature_1.kps, self.img2, self.feature_2.kps, self.matches,outImg=None)\n",
    "        cv2.imwrite(path, self.outImage)\n",
    "scene = Triangulation()\n",
    "\"\"\"\n",
    "n_components = JSON.parse(String(read(\"../config/config.json\")))[\"config\"][\"SIFTFeatures\"]\n",
    "\n",
    "pair = 1\n",
    "\n",
    "left = 5\n",
    "right = 4\n",
    "out_path = \"C:/Users/user/Documents/Research/FeatureCorrespondenes/data/dataset/pair_$(pair)/outMatched.png\"\n",
    "img1_path = \"C:/Users/user/Documents/Research/FeatureCorrespondenes/data/dataset/pair_$(pair)/left_000$(left)-small.png\"\n",
    "img2_path = \"C:/Users/user/Documents/Research/FeatureCorrespondenes/data/dataset/pair_$(pair)/right_000$(right)-small.png\"\n",
    "\n",
    "\n",
    "py\"scene.load_imgs\"(img1_path, img2_path)\n",
    "py\"scene.findRootSIFTFeatures\"(n_components=n_components)\n",
    "\n",
    "pts1 = py\"scene.feature_1.pos\"\n",
    "pts2 = py\"scene.feature_2.pos\"\n",
    "\n",
    "pts1 =py\"list\"(pts1)\n",
    "pts2 =py\"list\"(pts2)\n",
    "\n",
    "\n",
    "P_points = hcat(pts1...)'\n",
    "Q_points = hcat(pts2...)'\n",
    "\n",
    "println(\"size P points\", size(P_points))\n",
    "println(\"size Q points\", size(Q_points))\n",
    "\n",
    "cost = pairwise(Euclidean(), P_points, Q_points; dims=1)\n",
    "println(size(cost))\n",
    "P = ones(size(P_points,1))\n",
    "Q = ones(size(Q_points,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize a model with 201 rows, 10000 columns and 30000 nonzeros\r\n",
      "Variable types: 0 continuous, 10000 integer (0 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [1e+00, 6e+02]\r\n",
      "  Bounds range     [0e+00, 0e+00]\r\n",
      "  RHS range        [1e+00, 1e+02]\r\n",
      "Presolve time: 0.03s\r\n",
      "Presolved: 201 rows, 10000 columns, 30000 nonzeros\r\n",
      "Variable types: 0 continuous, 10000 integer (10000 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 2.710592e+03, 429 iterations, 0.01 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "*    0     0               0    2710.5922064 2710.59221  0.00%     -    0s\r\n",
      "Optimal solution found at node 0 - now completing solution pool...\r\n",
      "     0     0          -    0      2710.59221 2710.59221  0.00%     -    0s\r\n",
      "     0     0          -    0      2710.59221 2710.59221  0.00%     -    0s\r\n",
      "     0     2          -    0      2710.59221 2710.59221  0.00%     -    0s\r\n",
      "  8433  1610          -  248      2710.59221 2710.59221  0.00%   1.0    5s\r\n",
      " 18125  2382          -  683      2710.59221 2710.59221  0.00%   1.4   10s\r\n",
      " 28453  2275          - 1428      2710.59221 2710.59221  0.00%   1.7   15s\r\n",
      " 38266  2272     cutoff 1630      2710.59221 2711.59407  0.00%   1.9   20s\r\n",
      " 50010  1674     cutoff 2099      2710.59221 2711.59407  0.00%   2.0   25s\r\n",
      " 62180  1289     cutoff 2300      2710.59221 2712.90382  0.00%   2.1   30s\r\n",
      " 73132  1079     cutoff 2249      2710.59221 2713.00491  0.00%   2.2   35s\r\n",
      " 84779   807          - 2308      2710.59221 2713.43106  0.00%   2.3   40s\r\n",
      " 97308   653     cutoff 2233      2710.59221 2713.83756  0.00%   2.3   45s\r\n",
      " 108040   441     cutoff 2305      2710.59221 2713.96276  0.00%   2.3   50s\r\n",
      " 119722   319     cutoff 2262      2710.59221 2714.13838  0.00%   2.4   55s\r\n",
      " 130978   245     cutoff 2310      2710.59221 2714.31466  0.00%   2.4   60s\r\n",
      " 141362   123     cutoff 2273      2710.59221 2714.51141  0.00%   2.4   65s\r\n",
      " 152482     0     cutoff 2282      2710.59221 2714.74081  0.00%   2.4   70s\r\n",
      "\r\n",
      "Explored 156275 nodes (379653 simplex iterations) in 71.61 seconds\r\n",
      "Thread count was 20 (of 20 available processors)\r\n",
      "\r\n",
      "Solution count 100: 2710.59 2711.59 2711.72 ... 2715.02\r\n",
      "No other solutions better than 2714.82\r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-04)\r\n",
      "Best objective 2.710592206405e+03, best bound 2.710592206405e+03, gap 0.0000%\r\n",
      "18 solution(s) selected\n",
      "2713.0049100861756 current objective value\n",
      "2713.0 2710.0\n"
     ]
    }
   ],
   "source": [
    "solCount = 100\n",
    "# m = JuMP.direct_model(Gurobi.Optimizer(PoolSearchMode=2, PoolSolutions=solCount, SolutionNumber=0,PoolGap = 0.001))\n",
    "m = JuMP.direct_model(Gurobi.Optimizer(PoolSearchMode=2, PoolSolutions=solCount, SolutionNumber=0));\n",
    "\n",
    "@variable(m, X[axes(cost,1), axes(cost,2)] ≥ 0, Int);\n",
    "@objective(m, Min, cost ⋅ X);\n",
    "@constraint(m,sum(X) .== min(sum(P), sum(Q)));\n",
    "@constraint(m, X * ones(Int, length(Q)) .<= P);\n",
    "@constraint(m, X'ones(Int, length(P)) .<= Q);\n",
    "optimize!(m);\n",
    "solution_pool = zeros(solCount, length(P),length(Q))\n",
    "obj = objective_value(m)\n",
    "cnt = 0\n",
    "for i in 0:(solCount-1)\n",
    "    global cnt\n",
    "    setparam!(m.moi_backend.inner,\"SolutionNumber\", i)\n",
    "    xn = Gurobi.get_dblattrarray(m.moi_backend.inner, \"Xn\", 1, length(X))\n",
    "    xn_val = Gurobi.get_dblattr(m.moi_backend.inner, \"PoolObjVal\")\n",
    "    if(floor(xn_val) != floor(obj))\n",
    "        if floor(xn_val) - floor(obj) == 1 || floor(xn_val) - floor(obj) == 2\n",
    "            default = zeros(length(P),length(Q))\n",
    "            for i in 0:length(P)-1\n",
    "                default[i+1,:] = xn[(i*length(Q))+1:(i+1)*length(Q)]\n",
    "            end\n",
    "            solution_pool[i+1,:,:] = default\n",
    "            cnt+=1\n",
    "            continue\n",
    "        end\n",
    "        println(i , \" solution(s) selected\")\n",
    "        println(xn_val, \" current objective value\")\n",
    "        println(floor(xn_val),\" \",floor(obj))\n",
    "        break\n",
    "    end\n",
    "    default = zeros(length(P),length(Q))\n",
    "    for i in 0:length(P)-1\n",
    "        default[i+1,:] = xn[(i*length(Q))+1:(i+1)*length(Q)]\n",
    "    end\n",
    "    solution_pool[i+1,:,:] = default\n",
    "    cnt+=1\n",
    "end\n",
    "\n",
    "sol_pool = deepcopy(solution_pool[1:cnt,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/user/Documents/Research/FeatureCorrespondenes/data/dataset/pair_1/outMatched.png\n",
      "C:/Users/user/Documents/Research/FeatureCorrespondenes/data/dataset/pair_1/outMatched.png\n"
     ]
    }
   ],
   "source": [
    "for n_sol in 1:cnt\n",
    "    solOther = sparse(sol_pool[n_sol,:,:])\n",
    "    experiment_path = \"../data/dataset/pair_$(pair)/experiment/matchedPoints_$(n_sol).csv\"\n",
    "    sizeOf = min(size(P,1), size(Q,1))\n",
    "    matched_pts1 = zeros(sizeOf,2)\n",
    "    matched_pts2 = zeros(sizeOf,2)\n",
    "    i = 1\n",
    "    py\"\"\"\n",
    "    arr = []\n",
    "    \"\"\"\n",
    "    for (x,y,v) in zip(findnz(solOther)...)\n",
    "        x_pos = [P_points'[:,x][1], Q_points'[:,y][1]]\n",
    "        y_pos = [P_points'[:,x][2], Q_points'[:,y][2]]\n",
    "\n",
    "        # dmatch creating\n",
    "        queryId = x-1\n",
    "        trainId = y-1\n",
    "        distance = cost[x,y]\n",
    "    #     if(distance <= 10)\n",
    "        dmatch = py\"cv2.DMatch($(queryId), $(trainId),$(distance))\"\n",
    "        py\"arr.append\"(dmatch)\n",
    "        matched_pts1[i,:] = [floor(x_pos[1]) floor(y_pos[1])]\n",
    "        matched_pts2[i,:] = [floor(x_pos[2]) floor(y_pos[2])]\n",
    "        i+=1\n",
    "    #     end\n",
    "    end\n",
    "    py\"\"\"\n",
    "    scene.matches = arr\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    path = \"../data\\\\pair\\\\lastLPMatched.png\"\n",
    "    py\"scene.drawMatches\"(out_path)\n",
    "    println(out_path)\n",
    "\n",
    "\n",
    "    matched_final_1 = deepcopy(matched_pts1[1:i-1, :])\n",
    "    matched_final_2 = deepcopy(matched_pts2[1:i-1, :]);\n",
    "    df = DataFrame()\n",
    "    df.PX = matched_final_1[:,1]\n",
    "    df.PY = matched_final_1[:,2]\n",
    "    df.QX = matched_final_2[:,1]\n",
    "    df.QY = matched_final_2[:,2];\n",
    "#     print(size(df))\n",
    "    \n",
    "    if n_sol%10 == 0\n",
    "        println(n_sol)\n",
    "    end\n",
    "\n",
    "    CSV.write(experiment_path,  df, writeheader=false)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
