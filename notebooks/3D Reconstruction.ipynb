{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using Distances\n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using JuMP\n",
    "using Gurobi\n",
    "using CSV\n",
    "using Distances\n",
    "using DataFrames\n",
    "# using PyPlot\n",
    "using SparseArrays\n",
    "using Printf\n",
    "using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size P points(100, 2)\n",
      "size Q points(100, 2)\n"
     ]
    }
   ],
   "source": [
    "py\"\"\"\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class SceneReconstruction3D:\n",
    "\n",
    "    def __init__(self,K, dist):\n",
    "        self.K = K\n",
    "        self.K_inv = np.linalg.inv(K)\n",
    "        self.d = dist\n",
    "\n",
    "    def load_image_pair(self, img_path1, img_path2, use_pyr_down=True):\n",
    "        self.img1 = cv2.imread(img_path1, cv2.CV_8UC3)\n",
    "        self.img2 = cv2.imread(img_path2, cv2.CV_8UC3)\n",
    "\n",
    "        if self.img1 is None:\n",
    "            sys.exit(\"Image \" + img_path1 + \" could not be loaded.\")\n",
    "        if self.img2 is None:\n",
    "            sys.exit(\"Image \" + img_path2 + \" could not be loaded.\")\n",
    "\n",
    "        if len(self.img1.shape) == 2:\n",
    "            self.img1 = cv2.cvtColor(self.img1, cv2.COLOR_GRAY2BGR)\n",
    "            self.img2 = cv2.cvtColor(self.img2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        target_width = 500\n",
    "        if use_pyr_down and self.img1.shape[1] > target_width:\n",
    "            while self.img1.shape[1] > 2 * target_width:\n",
    "                self.img1 = cv2.pyrDown(self.img1)\n",
    "                self.img2 = cv2.pyrDown(self.img2)\n",
    "\n",
    "        self.img1 = cv2.undistort(self.img1, self.K, self.d)\n",
    "        self.img2 = cv2.undistort(self.img2, self.K, self.d)\n",
    "\n",
    "    def findRootSIFTFeatures(self):\n",
    "        class RootSIFT:\n",
    "            def __init__(self):\n",
    "                self.extractor = cv2.xfeatures2d.SIFT_create(100)\n",
    "\n",
    "            def compute(self, image, kps, eps=1e-7):\n",
    "                (kps, descs) = self.extractor.compute(image, kps)\n",
    "                if len(kps) == 0:\n",
    "                    return ([], None)\n",
    "\n",
    "                descs /= (descs.sum(axis=1, keepdims=True) + eps)\n",
    "                descs = np.sqrt(descs)\n",
    "                return (kps, descs)\n",
    "\n",
    "        class InnerFeatures:\n",
    "            def __init__(self, kps, des, pos):\n",
    "                self.kps = kps\n",
    "                self.des = des\n",
    "                self.pos = pos\n",
    "\n",
    "        def innerRootSIFT(img):\n",
    "            sift = cv2.xfeatures2d.SIFT_create(100)\n",
    "            (kps, descs) = sift.detectAndCompute(img, None)\n",
    "\n",
    "            rs = RootSIFT()\n",
    "            (kps, descs) = rs.compute(img, kps)\n",
    "            pos = np.float32([np.array([x.pt[0], x.pt[1]]) for x in kps])\n",
    "\n",
    "            # cleaning\n",
    "            return kps, descs, pos\n",
    "\n",
    "        kps1, desc1, pos1 = innerRootSIFT(self.img1)\n",
    "        kps2, desc2, pos2 = innerRootSIFT(self.img2)\n",
    "        self.feature_1 = InnerFeatures(kps1, desc1, pos1)\n",
    "        self.feature_2 = InnerFeatures(kps2, desc2, pos2)\n",
    "\n",
    "    def drawMatches(self, path):\n",
    "        self.outImage = cv2.drawMatches(self.img1, self.feature_1.kps, self.img2, self.feature_2.kps, self.matches,outImg=None)\n",
    "        cv2.imwrite(path, self.outImage)\n",
    "    \n",
    "    def _find_fundamental_matrix(self):\n",
    "        self.F, self.Fmask = cv2.findFundamentalMat(self.match_pts1,\n",
    "                                                    self.match_pts2,\n",
    "                                                    cv2.FM_RANSAC, 0.1, 0.99)\n",
    "\n",
    "    def _find_essential_matrix(self):\n",
    "        self.E = self.K.T.dot(self.F).dot(self.K)\n",
    "\n",
    "    def _find_camera_matrices_rt(self):\n",
    "        # decompose essential matrix into R, t (See Hartley and Zisserman 9.13)\n",
    "        U, S, Vt = np.linalg.svd(self.E)\n",
    "        W = np.array([0.0, -1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                      1.0]).reshape(3, 3)\n",
    "\n",
    "        # iterate over all point correspondences used in the estimation of the\n",
    "        # fundamental matrix\n",
    "        first_inliers = []\n",
    "        second_inliers = []\n",
    "        for i in range(len(self.Fmask)):\n",
    "            if self.Fmask[i]:\n",
    "                # normalize and homogenize the image coordinates\n",
    "                first_inliers.append(self.K_inv.dot([self.match_pts1[i][0],\n",
    "                                                     self.match_pts1[i][1], 1.0]))\n",
    "                second_inliers.append(self.K_inv.dot([self.match_pts2[i][0],\n",
    "                                                      self.match_pts2[i][1], 1.0]))\n",
    "\n",
    "        # Determine the correct choice of second camera matrix\n",
    "        # only in one of the four configurations will all the points be in\n",
    "        # front of both cameras\n",
    "        # First choice: R = U * Wt * Vt, T = +u_3 (See Hartley Zisserman 9.19)\n",
    "        R = U.dot(W).dot(Vt)\n",
    "        T = U[:, 2]\n",
    "        if not self._in_front_of_both_cameras(first_inliers, second_inliers,\n",
    "                                              R, T):\n",
    "            # Second choice: R = U * W * Vt, T = -u_3\n",
    "            T = - U[:, 2]\n",
    "\n",
    "        if not self._in_front_of_both_cameras(first_inliers, second_inliers,\n",
    "                                              R, T):\n",
    "            # Third choice: R = U * Wt * Vt, T = u_3\n",
    "            R = U.dot(W.T).dot(Vt)\n",
    "            T = U[:, 2]\n",
    "\n",
    "            if not self._in_front_of_both_cameras(first_inliers,\n",
    "                                                  second_inliers, R, T):\n",
    "                # Fourth choice: R = U * Wt * Vt, T = -u_3\n",
    "                T = - U[:, 2]\n",
    "\n",
    "        self.match_inliers1 = first_inliers\n",
    "        self.match_inliers2 = second_inliers\n",
    "        self.Rt1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "        self.Rt2 = np.hstack((R, T.reshape(3, 1)))\n",
    "\n",
    "    def _in_front_of_both_cameras(self, first_points, second_points, rot,trans):\n",
    "        rot_inv = rot\n",
    "        for first, second in zip(first_points, second_points):\n",
    "            first_z = np.dot(rot[0, :] - second[0] * rot[2, :],trans) / np.dot(rot[0, :] - second[0] * rot[2, :],second)\n",
    "            first_3d_point = np.array([first[0] * first_z,second[0] * first_z, first_z])\n",
    "            second_3d_point = np.dot(rot.T, first_3d_point) - np.dot(rot.T,trans)\n",
    "\n",
    "            if first_3d_point[2] < 0 or second_3d_point[2] < 0:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "K = np.array([[2759.48/4, 0, 1520.69/4, 0, 2764.16/4,1006.81/4, 0, 0, 1]]).reshape(3, 3)\n",
    "d = np.array([0.0, 0.0, 0.0, 0.0, 0.0]).reshape(1, 5)\n",
    "scene = SceneReconstruction3D(K,d)\n",
    "\n",
    "\"\"\"\n",
    "img1_path = \"../data/pair/Left.png\"\n",
    "img2_path = \"../data/pair/Right.png\"\n",
    "\n",
    "py\"scene.load_image_pair\"(img1_path, img2_path)\n",
    "py\"scene.findRootSIFTFeatures()\"\n",
    "\n",
    "pts1 = py\"scene.feature_1.pos\"\n",
    "pts2 = py\"scene.feature_2.pos\";\n",
    "\n",
    "P_points = pts1\n",
    "Q_points = pts2\n",
    "\n",
    "println(\"size P points\", size(P_points))\n",
    "println(\"size Q points\", size(Q_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "cost = pairwise(Euclidean(), P_points, Q_points; dims=1)\n",
    "println(size(cost))\n",
    "P = ones(size(P_points,1))\n",
    "Q = ones(size(Q_points,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize a model with 201 rows, 10000 columns and 30000 nonzeros\r\n",
      "Variable types: 0 continuous, 10000 integer (0 binary)\r\n",
      "Coefficient statistics:\r\n",
      "  Matrix range     [1e+00, 1e+00]\r\n",
      "  Objective range  [2e+00, 8e+02]\r\n",
      "  Bounds range     [0e+00, 0e+00]\r\n",
      "  RHS range        [1e+00, 1e+02]\r\n",
      "Presolve time: 0.03s\r\n",
      "Presolved: 201 rows, 10000 columns, 30000 nonzeros\r\n",
      "Variable types: 0 continuous, 10000 integer (10000 binary)\r\n",
      "\r\n",
      "Root relaxation: objective 1.054019e+04, 780 iterations, 0.02 seconds\r\n",
      "\r\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\r\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\r\n",
      "\r\n",
      "*    0     0               0    10540.194381 10540.1944  0.00%     -    0s\r\n",
      "Optimal solution found at node 0 - now completing solution pool...\r\n",
      "     0     0          -    0      10540.1944 10540.1944  0.00%     -    0s\r\n",
      "     0     0          -    0      10540.1944 10540.1944  0.00%     -    0s\r\n",
      "     0     2          -    0      10540.1944 10540.1944  0.00%     -    0s\r\n",
      "\r\n",
      "Explored 352 nodes (1275 simplex iterations) in 0.19 seconds\r\n",
      "Thread count was 20 (of 20 available processors)\r\n",
      "\r\n",
      "Solution count 10: 10540.2 10540.2 10540.2 ... 10540.4\r\n",
      "\r\n",
      "Optimal solution found (tolerance 1.00e-04)\r\n",
      "Best objective 1.054019438052e+04, best bound 1.054019438052e+04, gap 0.0000%\r\n",
      "5 solution(s) selected\n"
     ]
    }
   ],
   "source": [
    "solCount = 10\n",
    "# m = JuMP.direct_model(Gurobi.Optimizer(PoolSearchMode=2, PoolSolutions=solCount, SolutionNumber=0,PoolGap = 0.001))\n",
    "m = JuMP.direct_model(Gurobi.Optimizer(PoolSearchMode=2, PoolSolutions=solCount, SolutionNumber=0))\n",
    "\n",
    "@variable(m, X[axes(cost,1), axes(cost,2)] ≥ 0, Int)\n",
    "@objective(m, Min, cost ⋅ X)\n",
    "@constraint(m,sum(X) .== min(sum(P), sum(Q)))\n",
    "@constraint(m, X * ones(Int, length(Q)) .<= P)\n",
    "@constraint(m, X'ones(Int, length(P)) .<= Q);\n",
    "optimize!(m)\n",
    "solution_pool = zeros(solCount, length(P),length(Q))\n",
    "cnt = 0\n",
    "obj = objective_value(m)\n",
    "\n",
    "for i in 0:(solCount-1)\n",
    "    try\n",
    "        setparam!(m.moi_backend.inner,\"SolutionNumber\", i)\n",
    "        xn = Gurobi.get_dblattrarray(m.moi_backend.inner, \"Xn\", 1, length(X))\n",
    "        xn_val = Gurobi.get_dblattr(m.moi_backend.inner, \"PoolObjVal\")\n",
    "        if(round(xn_val,digits=1) != round(obj, digits=1))\n",
    "            println(cnt , \" solution(s) selected\")\n",
    "            break\n",
    "        end\n",
    "        default = zeros(length(P),length(Q))\n",
    "        for i in 0:length(P)-1\n",
    "            default[i+1,:] = xn[(i*length(Q))+1:(i+1)*length(Q)]\n",
    "        end\n",
    "        solution_pool[i+1,:,:] = default\n",
    "        cnt+=1\n",
    "    catch \n",
    "        break\n",
    "    end\n",
    "end\n",
    "sol_pool = deepcopy(solution_pool[1:cnt,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "solOther = sparse(sol_pool[3,:,:])\n",
    "sizeOf = min(size(P,1), size(Q,1))\n",
    "matched_pts1 = zeros(sizeOf,2)\n",
    "matched_pts2 = zeros(sizeOf,2)\n",
    "i = 1\n",
    "py\"\"\"\n",
    "arr = []\n",
    "\"\"\"\n",
    "for (x,y,v) in zip(findnz(solOther)...)\n",
    "    x_pos = [P_points'[:,x][1], Q_points'[:,y][1]]\n",
    "    y_pos = [P_points'[:,x][2], Q_points'[:,y][2]]\n",
    "    \n",
    "    # dmatch creating\n",
    "    queryId = x-1\n",
    "    trainId = y-1\n",
    "    distance = cost[x,y]\n",
    "    dmatch = py\"cv2.DMatch($(queryId), $(trainId),$(distance))\"\n",
    "    py\"arr.append\"(dmatch)\n",
    "    \n",
    "    matched_pts1[i,:] = [floor(x_pos[1]) floor(y_pos[1])]\n",
    "    matched_pts2[i,:] = [floor(x_pos[2]) floor(y_pos[2])]\n",
    "    i+=1\n",
    "end\n",
    "py\"\"\"\n",
    "scene.matches = arr\n",
    "\"\"\"\n",
    "path = \"../data\\\\pair\\\\matchedByLP3.png\"\n",
    "py\"scene.drawMatches\"(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()\n",
    "df.PX = matched_pts1[:,1]\n",
    "df.PY = matched_pts1[:,2]\n",
    "df.QX = matched_pts2[:,1]\n",
    "df.QY = matched_pts2[:,2];\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"../data/pair/matchedPoints.csv\",  df, writeheader=false)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
