{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using Distances\n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using JuMP\n",
    "using Gurobi\n",
    "using CSV\n",
    "using Distances\n",
    "using PyPlot\n",
    "using SparseArrays\n",
    "using Printf\n",
    "using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:21: RuntimeWarning: invalid value encountered in sqrt\r\n"
     ]
    }
   ],
   "source": [
    "py\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class InnerFeatures:\n",
    "    def __init__(self, kps, des, pos):\n",
    "        self.kps = kps\n",
    "        self.des = des\n",
    "        self.pos = pos\n",
    "\n",
    "class RootSIFT:\n",
    "    def __init__(self):\n",
    "        self.extractor = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    def compute(self, image, kps, eps=1e-7):\n",
    "        (kps, descs) = self.extractor.compute(image, kps)\n",
    "        if len(kps) == 0:\n",
    "            return ([], None)\n",
    "\n",
    "        descs /= (descs.sum(axis=1, keepdims=True) + eps)\n",
    "        descs = np.sqrt(descs)\n",
    "        return (kps, descs)\n",
    "\n",
    "class SceneReconstruction3D:\n",
    "    def __init__(self, K, d):\n",
    "        self.K = K\n",
    "        self.K_inv = np.linalg.inv(K)\n",
    "        self.d = d\n",
    "\n",
    "    def loadImgs(self, img1_path, img2_path, scale = 10):\n",
    "\n",
    "        img1 = cv2.cvtColor(cv2.imread(img1_path), cv2.COLOR_BGR2GRAY)\n",
    "        width = int(img1.shape[1] * scale / 100)\n",
    "        height = int(img1.shape[0] * scale / 100)\n",
    "        dim = (width, height)\n",
    "        self.img1 = cv2.resize(img1, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        img2 = cv2.cvtColor(cv2.imread(img2_path), cv2.COLOR_BGR2GRAY)\n",
    "        width = int(img2.shape[1] * scale / 100)\n",
    "        height = int(img2.shape[0] * scale / 100)\n",
    "        dim = (width, height)\n",
    "        self.img2 = cv2.resize(img2, dim, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def rootSIFT(self):\n",
    "        def innerRootSIFT(img):\n",
    "            sift = cv2.xfeatures2d.SIFT_create()\n",
    "            (kps, descs) = sift.detectAndCompute(img, None)\n",
    "\n",
    "            rs = RootSIFT()\n",
    "            (kps, descs) = rs.compute(img, kps)\n",
    "            pos = [np.array([x.pt[0], x.pt[1]]) for x in kps]\n",
    "\n",
    "            return kps, descs, np.array(pos)\n",
    "        kps1, desc1, pos1 = innerRootSIFT(self.img1)\n",
    "        kps2, desc2, pos2 = innerRootSIFT(self.img2)\n",
    "        self.feature_1 = InnerFeatures(kps1, desc1, pos1)\n",
    "        self.feature_2 = InnerFeatures(kps2, desc2, pos2)\n",
    "\n",
    "    def LPMatcher(self, pts1, pts2):\n",
    "        self.match_pts1 = np.array(pts1)\n",
    "        self.match_pts2 = np.array(pts2)\n",
    "\n",
    "    def fundamental_matrix(self):\n",
    "        self.F, self.Fmask = cv2.findFundamentalMat(self.match_pts1,\n",
    "                                                    self.match_pts2,\n",
    "                                                    cv2.FM_RANSAC, 0.1, 0.99)\n",
    "    def essential_matrix(self):\n",
    "        self.E = self.K.T.dot(self.F).dot(self.K)\n",
    "\n",
    "    def _find_camera_matrices_rt(self):\n",
    "        # decompose essential matrix into R, t (See Hartley and Zisserman 9.13)\n",
    "        U, S, Vt = np.linalg.svd(self.E)\n",
    "        W = np.array([0.0, -1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
    "                      1.0]).reshape(3, 3)\n",
    "\n",
    "        # iterate over all point correspondences used in the estimation of the\n",
    "        # fundamental matrix\n",
    "        first_inliers = []\n",
    "        second_inliers = []\n",
    "        for i in range(len(self.Fmask)):\n",
    "            if self.Fmask[i]:\n",
    "                # normalize and homogenize the image coordinates\n",
    "                first_inliers.append(self.K_inv.dot([self.match_pts1[i][0],\n",
    "                                     self.match_pts1[i][1], 1.0]))\n",
    "                second_inliers.append(self.K_inv.dot([self.match_pts2[i][0],\n",
    "                                      self.match_pts2[i][1], 1.0]))\n",
    "\n",
    "        # Determine the correct choice of second camera matrix\n",
    "        # only in one of the four configurations will all the points be in\n",
    "        # front of both cameras\n",
    "        # First choice: R = U * Wt * Vt, T = +u_3 (See Hartley Zisserman 9.19)\n",
    "        R = U.dot(W).dot(Vt)\n",
    "        T = U[:, 2]\n",
    "    \n",
    "\n",
    "        self.match_inliers1 = first_inliers\n",
    "        self.match_inliers2 = second_inliers\n",
    "        self.Rt1 = np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "        self.Rt2 = np.hstack((R, T.reshape(3, 1)))\n",
    "    \n",
    "    def triangulation(self):\n",
    "        first_inliers = np.array(self.match_inliers1).reshape(-1, 3)[:, :2]\n",
    "        second_inliers = np.array(self.match_inliers2).reshape(-1, 3)[:, :2]\n",
    "        \n",
    "        self.pts4D = cv2.triangulatePoints(self.Rt1, self.Rt2, first_inliers.T,second_inliers.T).T\n",
    "        self.pts3D = self.pts4D[:, :3]/np.repeat(self.pts4D[:, 3], 3).reshape(-1, 3)\n",
    "\n",
    "        self.Ys = self.pts3D[:, 0]\n",
    "        self.Zs = self.pts3D[:, 1]\n",
    "        self.Xs = self.pts3D[:, 2]\n",
    "\n",
    "K = np.array([[2759.48/4, 0, 1520.69/4, 0, 2764.16/4,1006.81/4, 0, 0, 1]]).reshape(3, 3)\n",
    "d = np.array([0.0, 0.0, 0.0, 0.0, 0.0]).reshape(1, 5)\n",
    "scene = SceneReconstruction3D(K,d)\n",
    "\"\"\"\n",
    "\n",
    "img1_path = \"../data/test/Left.png\"\n",
    "img2_path = \"../data/test/Right.png\"\n",
    "\n",
    "py\"scene.loadImgs\"(img1_path, img2_path)\n",
    "py\"scene.rootSIFT()\"\n",
    "\n",
    "pts1 = py\"scene.feature_1.pos\"\n",
    "pts2 = py\"scene.feature_2.pos\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cleaning(original)\n",
    "    res_dict = Dict()\n",
    "    for i in 1:size(original, 1)\n",
    "        res_dict[hash(original[i,:])] = original[i,:]\n",
    "    end\n",
    "    \n",
    "    vals = collect(values(res_dict))\n",
    "    output = zeros(size(vals,1), 2)\n",
    "    for i in 1:size(vals,1)\n",
    "        output[i,:] = [vals[i][1],vals[i][2]]\n",
    "    end\n",
    "    \n",
    "    return output\n",
    "end\n",
    "\n",
    "P_points = cleaning(pts1)\n",
    "Q_points = cleaning(pts2)\n",
    "\n",
    "cost = pairwise(Euclidean(), P_points, Q_points; dims=1)\n",
    "\n",
    "P = ones(size(P_points,1))\n",
    "Q = ones(size(Q_points,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize a model with 418 rows, 43452 columns and 130356 nonzeros\n",
      "Variable types: 0 continuous, 43452 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [3e-01, 3e+02]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 2e+02]\n",
      "Presolve time: 0.13s\n",
      "Presolved: 418 rows, 43452 columns, 130356 nonzeros\n",
      "Variable types: 0 continuous, 43452 integer (43452 binary)\n",
      "\n",
      "Starting sifting (using dual simplex for sub-problems)...\n",
      "\n",
      "    Iter     Pivots    Primal Obj      Dual Obj        Time\n",
      "       0          0     infinity      0.0000000e+00      0s\n",
      "       1        663   2.0001747e+07   5.8366760e+02      0s\n",
      "       2       1822   7.0025469e+06   8.2611698e+02      0s\n",
      "       3       3011   7.0025469e+06   9.9460776e+02      0s\n",
      "       4       4223   4.0030331e+06   1.1211124e+03      0s\n",
      "       5       5451   4.0029843e+06   1.2305567e+03      0s\n",
      "       6       6747   3.9757969e+03   1.4213045e+03      0s\n",
      "       7       7402   3.8309260e+03   2.2007092e+03      0s\n",
      "       8       8065   3.6965635e+03   3.3431931e+03      0s\n",
      "       9       8576   3.6839972e+03   3.6790170e+03      0s\n",
      "\n",
      "Sifting complete\n",
      "\n",
      "\n",
      "Root relaxation: objective 3.683997e+03, 8986 iterations, 0.12 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "*    0     0               0    3683.9972426 3683.99724  0.00%     -    0s\n",
      "Optimal solution found at node 0 - now completing solution pool...\n",
      "     0     0          -    0      3683.99724 3683.99724  0.00%     -    0s\n",
      "     0     0          -    0      3683.99724 3683.99724  0.00%     -    0s\n",
      "     0     2          -    0      3683.99724 3683.99724  0.00%     -    0s\n",
      "  2565   494          -  235      3683.99724 3683.99724  0.00%   1.1    5s\n",
      "  4315   667 3683.99724  384    0 3683.99724 3683.99724  0.00%   1.3   10s\n",
      "  6213   397          -  389      3683.99724 3683.99724  0.00%   3.4   15s\n",
      "  8291   752     cutoff  393      3683.99724 3683.99724  0.00%   2.8   20s\n",
      " 10509   493     cutoff  858      3683.99724 3683.99724  0.00%   2.7   25s\n",
      "\n",
      "Explored 11307 nodes (39085 simplex iterations) in 26.27 seconds\n",
      "Thread count was 20 (of 20 available processors)\n",
      "\n",
      "Solution count 10: 3684 3684.01 3684.25 ... 3684.35\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.683997242574e+03, best bound 3.683997242574e+03, gap 0.0000%\n",
      "2 solution(s) selected\n"
     ]
    }
   ],
   "source": [
    "solCount = 10\n",
    "# m = JuMP.direct_model(Gurobi.Optimizer(PoolSearchMode=2, PoolSolutions=solCount, SolutionNumber=0,PoolGap = 0.001))\n",
    "m = JuMP.direct_model(Gurobi.Optimizer(PoolSearchMode=2, PoolSolutions=solCount, SolutionNumber=0))\n",
    "\n",
    "@variable(m, X[axes(cost,1), axes(cost,2)] ≥ 0, Int)\n",
    "@objective(m, Min, cost ⋅ X)\n",
    "@constraint(m,sum(X) .== min(sum(P), sum(Q)))\n",
    "@constraint(m, X * ones(Int, length(Q)) .<= P)\n",
    "@constraint(m, X'ones(Int, length(P)) .<= Q);\n",
    "optimize!(m)\n",
    "solution_pool = zeros(solCount, length(P),length(Q))\n",
    "cnt = 0\n",
    "obj = objective_value(m)\n",
    "\n",
    "for i in 0:(solCount-1)\n",
    "    try\n",
    "        setparam!(m.moi_backend.inner,\"SolutionNumber\", i)\n",
    "        xn = Gurobi.get_dblattrarray(m.moi_backend.inner, \"Xn\", 1, length(X))\n",
    "        xn_val = Gurobi.get_dblattr(m.moi_backend.inner, \"PoolObjVal\")\n",
    "        if(round(xn_val,digits=1) != round(obj, digits=1))\n",
    "            println(cnt , \" solution(s) selected\")\n",
    "            break\n",
    "        end\n",
    "        default = zeros(length(P),length(Q))\n",
    "        for i in 0:length(P)-1\n",
    "            default[i+1,:] = xn[(i*length(Q))+1:(i+1)*length(Q)]\n",
    "        end\n",
    "        solution_pool[i+1,:,:] = default\n",
    "        cnt+=1\n",
    "    catch \n",
    "        break\n",
    "    end\n",
    "end\n",
    "sol_pool = deepcopy(solution_pool[1:cnt,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "solOther = sparse(sol_pool[rand(1:cnt),:,:])\n",
    "sizeOf = min(size(P,1), size(Q,1))\n",
    "matched_pts1 = zeros(sizeOf,2)\n",
    "matched_pts2 = zeros(sizeOf,2)\n",
    "i = 1\n",
    "\n",
    "for (x,y,v) in zip(findnz(solOther)...)\n",
    "    x_pos = [P_points'[:,x][1], Q_points'[:,y][1]]\n",
    "    y_pos = [P_points'[:,x][2], Q_points'[:,y][2]]\n",
    "    matched_pts1[i,:] = [x_pos[1] y_pos[1]]\n",
    "    matched_pts2[i,:] = [x_pos[2] y_pos[2]]\n",
    "    i+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×3 Array{Float64,2}:\n",
       " -0.238992  -0.229236   0.689113\n",
       " -0.229348  -0.250553   0.709517\n",
       " -0.238426  -0.136837   0.734001\n",
       " -0.217765  -0.0847705  0.763422\n",
       " -0.271974  -0.140198   0.574359\n",
       " -0.228074  -0.218879   0.742163\n",
       " -0.244259  -0.132584   0.711965\n",
       " -0.246918  -0.128886   0.693669\n",
       " -0.24229   -0.234012   0.670116\n",
       " -0.264068  -0.150728   0.599356\n",
       " -0.234778  -0.139123   0.745574\n",
       " -0.260743  -0.129014   0.535339\n",
       " -0.246236  -0.131141   0.704545\n",
       " -0.241264  -0.199816   0.689403\n",
       " -0.239219  -0.223919   0.68993 \n",
       " -0.205044  -0.126856   0.862429\n",
       " -0.238387  -0.233521   0.689152\n",
       " -0.233321  -0.141721   0.736731\n",
       " -0.243598  -0.134109   0.719557"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py\"scene.LPMatcher\"(matched_pts1, matched_pts2)\n",
    "py\"scene.fundamental_matrix()\"\n",
    "py\"scene.essential_matrix()\"\n",
    "py\"scene._find_camera_matrices_rt()\"\n",
    "py\"scene.triangulation()\"\n",
    "py\"scene.pts3D\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
